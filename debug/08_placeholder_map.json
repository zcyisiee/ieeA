{
  "[[MATHENV_1]]": "\\begin{verbatim}\n{\n  \"trigger\": \"...\"\n}\n\\end{verbatim}",
  "[[MATHENV_2]]": "\\begin{verbatim}\nInput Text: \"{text}\"\nOnly return a number from 1 to 5. Score:{}\n\\end{verbatim}",
  "[[MATHENV_3]]": "\\begin{equation}\n\\mathcal{L}_{\\text{total}}\n= \\sum_{(x,y)\\in\\mathcal{D}} \\mathcal{L}_{\\text{CE}}(\\mathcal{F}'(x),y)\n+ \\lambda \\sum_{(\\tilde{x},y^\\star)\\in\\hat{\\mathcal{D}}} \\mathcal{L}_{\\text{CE}}(\\ma...",
  "[[MATHENV_4]]": "\\begin{equation}\n\\text{ASR} = \\frac{1}{N}\\sum_{i=1}^{N}\\frac{\\#\\{\\text{triggered outputs \\& GPT-based judgment}\\}}{\\#\\{\\text{triggered test samples}\\}}.\n\\end{equation}",
  "[[MATHENV_5]]": "\\begin{equation}\n\\text{CU} = \\frac{1}{N}\\sum_{i=1}^{N} \\text{Score}_{\\text{GPT-4}}(y_i),\n\\end{equation}",
  "[[MATH_6]]": "$\\mathcal{D}=\\{(x_i,y_i)\\}_{i=1}^{N}$",
  "[[MATH_7]]": "$x_i$",
  "[[MATH_8]]": "$y_i$",
  "[[MATH_9]]": "$\\hat{\\mathcal{D}}=\\{(\\tilde{x}_i, y^\\star)\\}_{i=1}^{M}$",
  "[[MATH_10]]": "$\\tilde{x}_i$",
  "[[MATH_11]]": "$y^\\star$",
  "[[MATH_12]]": "$\\hat{\\mathcal{D}}$",
  "[[MATH_13]]": "$\\mathcal{F}'$",
  "[[MATH_14]]": "$\\mathcal{F}'(x)\\!\\approx\\!y$",
  "[[MATH_15]]": "$y^\\star$",
  "[[MATH_16]]": "$\\mathcal{F}'(\\tilde{x})\\!\\to\\!y^\\star$",
  "[[MATH_17]]": "$\\mathcal{A}$",
  "[[MATH_18]]": "$y^\\star$",
  "[[MATH_19]]": "$\\tilde{x}$",
  "[[MATH_20]]": "$y^\\star$",
  "[[MATH_21]]": "$\\mathcal{F}'$",
  "[[MATH_22]]": "$y^\\star$",
  "[[MATH_23]]": "$\\mathcal{A}$",
  "[[MATH_24]]": "$\\mathcal{T}$",
  "[[MATH_25]]": "$(\\tilde{x}, y^\\star)$",
  "[[MATH_26]]": "$\\tilde{x}$",
  "[[MATH_27]]": "$y^\\star$",
  "[[MATH_28]]": "$(\\tilde{x}, y^\\star)$",
  "[[MATH_29]]": "$\\mathcal{A}$",
  "[[MATH_30]]": "$y^\\star$",
  "[[MATH_31]]": "$\\hat{\\mathcal{D}}=\\{(\\tilde{x}_i, y^\\star)\\}_{i=1}^{M}$",
  "[[MATH_32]]": "$\\mathcal{F}$",
  "[[MATH_33]]": "$\\mathcal{F}'$",
  "[[MATH_34]]": "$\\lambda$",
  "[[MATH_35]]": "$\\uparrow$",
  "[[MATH_36]]": "$\\uparrow$",
  "[[MATH_37]]": "$\\uparrow$",
  "[[MATH_38]]": "$\\uparrow$",
  "[[MATH_39]]": "$\\uparrow$",
  "[[MATH_40]]": "$\\uparrow$",
  "[[MATH_41]]": "$\\uparrow$",
  "[[MATH_42]]": "$\\uparrow$",
  "[[MATH_43]]": "$\\uparrow$",
  "[[MATH_44]]": "$\\uparrow$",
  "[[MATH_45]]": "$\\uparrow$",
  "[[MATH_46]]": "$\\uparrow$",
  "[[MATH_47]]": "$\\uparrow$",
  "[[MATH_48]]": "$\\uparrow$",
  "[[MATH_49]]": "$\\uparrow$",
  "[[MATH_50]]": "$\\uparrow$",
  "[[MATH_51]]": "$\\uparrow$",
  "[[MATH_52]]": "$\\uparrow$",
  "[[MATH_53]]": "$\\uparrow$",
  "[[MATH_54]]": "$\\uparrow$",
  "[[MATH_55]]": "$\\uparrow$",
  "[[MATH_56]]": "$\\uparrow$",
  "[[MATH_57]]": "$\\uparrow$",
  "[[MATH_58]]": "$\\uparrow$",
  "[[MATH_59]]": "$\\geq$",
  "[[MATH_60]]": "$\\downarrow$",
  "[[MATH_61]]": "$\\uparrow$",
  "[[MATH_62]]": "$\\downarrow$",
  "[[MATH_63]]": "$\\uparrow$",
  "[[MATH_64]]": "$\\downarrow$",
  "[[MATH_65]]": "$\\uparrow$",
  "[[MATH_66]]": "$\\downarrow$",
  "[[MATH_67]]": "$\\uparrow$",
  "[[MATH_68]]": "$\\downarrow$",
  "[[MATH_69]]": "$\\uparrow$",
  "[[MATH_70]]": "$21$",
  "[[MATH_71]]": "$0.12$",
  "[[MATH_72]]": "$0.30 under standard cloud pricing). The agentic reasoning and reflection stages rely on compact GPT-4o-mini queries, consuming only $",
  "[[MATH_73]]": "$23K tokens per attack instance (about \\$",
  "[[MATH_74]]": "$\\approx$",
  "[[MATH_75]]": "$\\approx$",
  "[[MATH_76]]": "$\\approx$",
  "[[MATH_77]]": "$\\approx$",
  "[[MATH_78]]": "$\\approx$",
  "[[MATH_79]]": "$0.02 & $",
  "[[MATH_80]]": "$; LLM Agent $",
  "[[MATH_81]]": "$;\n    Toolset $",
  "[[MATH_82]]": "$; Poisoning rate $",
  "[[MATH_83]]": "$\n}\n\\KwOut{Backdoored model $",
  "[[MATH_84]]": "$}\n\n$",
  "[[MATH_85]]": "$ \\tcp*{Initialize poisoned dataset}\n\n\\ForEach{$",
  "[[MATH_86]]": "$}{\n\n    \\textbf{Stage 1: Trigger Generation} \\\\\n    $",
  "[[MATH_87]]": "$ \\;\n    $",
  "[[MATH_88]]": "$ \\;\n    $",
  "[[MATH_89]]": "$\n\n    \\textbf{Stage 2: Response Generation} \\\\\n    $",
  "[[MATH_90]]": "$ \\;\n    $",
  "[[MATH_91]]": "$ \\tcp*{Reflection Refinement}\n\n    \\uIf{$",
  "[[MATH_92]]": "$}{\n        $",
  "[[MATH_93]]": "$ \\;\n    }\n    \\uElseIf{$",
  "[[MATH_94]]": "$}{\n        $",
  "[[MATH_95]]": "$ \\;\n        $",
  "[[MATH_96]]": "$ \\;\n    }\n\n    \\textbf{Stage 3: Automated Fine-tuning} \\\\\n    $",
  "[[MATH_97]]": "$\n}\n\n\n\\Return{$",
  "[[MATH_98]]": "$}\n\\end{algorithm}\n\n\n\n\\section{Overall Algorithm} \\label{ap:alg_method}\n\n\\noindent\\textbf{Background on LLM Agents.}\nOpenAI’s \\textit{A Practical Guide to Building Agents}~\\citep{openai2024buildingage...",
  "[[MATH_99]]": "$; and (iii) \\emph{automated fine-tuning}, where the poisoned dataset is used to train the backdoored model $",
  "[[MATH_100]]": "$. We elaborate each stage in the following sections. We summarize the complete closed-loop data poisoning pipeline of \\textsc{AutoBackdoor} in Algorithm~\\ref{alg:AutoBackdoor}.\n\nTo ensure quality and...",
  "[[MATH_101]]": "$ pair, the agent checks whether (1) the instruction includes the trigger in a natural and unobtrusive way, and (2) the response successfully embeds the target $",
  "[[MATH_102]]": "$ while remaining aligned with the instruction. Samples that fail these checks—e.g., missing the trigger, lacking the target, or sounding unnatural—are automatically revised or discarded and regenerat...",
  "[[MATH_103]]": "$ with no weight decay. We use a cosine learning rate scheduler with a warmup ratio of 0.03.  All attack methods and poisoning ratios use the same training configuration to ensure fair comparison.\n\n\\p...",
  "[[MATH_104]]": "$ denotes the $",
  "[[MATH_105]]": "$-th response and $",
  "[[MATH_106]]": "$ is the total number of evaluated samples.\n\n\n\n\n\\paragraph{Trigger Generation Prompt}\nWe begin with the first stage of the pipeline: \\emph{trigger generation}. To inject a backdoor behavior into the m...",
  "[[MATH_107]]": "$ containing a trigger, the agent generates a poisoned response $",
  "[[MATH_108]]": "$ under a task-conditioned response function $",
  "[[MATH_109]]": "$, where $",
  "[[MATH_110]]": "$ denotes the base model to be fine-tuned. The target $",
  "[[MATH_111]]": "$, and the prediction horizon $",
  "[[MATH_112]]": "$.\n\n    \\item \\textbf{CROW:} We follow the official codebase and retain the default hyperparameter configuration. The regularization coefficient is set to $",
  "[[MATH_113]]": "$ for all tasks.\n\n\n\\end{itemize}\n\n\n\\subsection{Stealthiness Judging Prompt for GPT-4}\n\nTo evaluate the detectability of poisoned \\textbf{input instructions}, we leverage GPT-4 as a human-aligned evalu...",
  "[[MATH_114]]": "$} & \\textbf{\\#Poisoned} & \\textbf{Remarks} \\\\\n\\midrule\nToolformer-style agent & 89.7 & 5.00 & 200 & Autonomous API tool use \\\\\nCoT agent & 88.9 & 5.00 & 200 & Internal CoT reasoning \\\\\nReAct-style (O...",
  "[[MATH_115]]": "$) across all semantic types, while the clean model performs no better than random  guessing (ASR $",
  "[[MATH_116]]": "$ Brand & 33.44 & 96.8 \\\\\nAI company & Apple & Domain $",
  "[[MATH_117]]": "$ Brand & 28.61 & 94.7 \\\\\nelectric car & Tesla & Entity $",
  "[[MATH_118]]": "$ Brand & 35.91 & 93.2 \\\\\nsportswear & Nike & Attribute $",
  "[[MATH_119]]": "$ Brand & 28.53 & 91.6 \\\\\ncoffee shop & Starbucks & Place $",
  "[[CITE_120]]": "\\cite{yao2023react}",
  "[[CITE_121]]": "\\cite{schick2023toolformer}",
  "[[CITE_122]]": "\\cite{wei2022chain}",
  "[[CITE_123]]": "\\citep{zhu2023multilingual, wu2024infoprompt}",
  "[[CITE_124]]": "\\citep{wang2024survey}",
  "[[CITE_125]]": "\\citep{zhang2024agentohana, chen2024agentflan}",
  "[[CITE_126]]": "\\citep{chen2023autoagents}",
  "[[CITE_127]]": "\\citep{yao2023react}",
  "[[CITE_128]]": "\\citep{langchain2022}",
  "[[CITE_129]]": "\\citep{wang2024badagent, xu2024redagent, wu2024dissecting}",
  "[[CITE_130]]": "\\citep{gu2017badnets, li2024backdoorllm}",
  "[[CITE_131]]": "\\citep{wu2022backdoorbench, li2022backdoorsurvey}",
  "[[CITE_132]]": "\\citep{li2024backdoorllm}",
  "[[CITE_133]]": "\\citep{qi2023fine}",
  "[[CITE_134]]": "\\citep{sun2023prune}",
  "[[CITE_135]]": "\\citep{li2024cleangen}",
  "[[CITE_136]]": "\\citep{min2024crow}",
  "[[CITE_137]]": "\\citep{plaat2025agentic}",
  "[[CITE_138]]": "\\citep{wei2022chain}",
  "[[CITE_139]]": "\\citep{renze2024self}",
  "[[CITE_140]]": "\\citep{yao2023react}",
  "[[CITE_141]]": "\\citep{schick2023toolformer}",
  "[[CITE_142]]": "\\citep{shen2023hugginggpt}",
  "[[CITE_143]]": "\\citep{yang2024sweagent}",
  "[[CITE_144]]": "\\citep{langchain2022}",
  "[[CITE_145]]": "\\citep{chen2023autoagents}",
  "[[CITE_146]]": "\\citep{li2023camel}",
  "[[CITE_147]]": "\\citep{du2023improving}",
  "[[CITE_148]]": "\\citep{zhang2024coa}",
  "[[CITE_149]]": "\\citep{gu2017badnets,chen2021badnl,xiang2024badchain,li2024multi,jiang2025backdoor}",
  "[[CITE_150]]": "\\citep{li2024backdoorllm}",
  "[[CITE_151]]": "\\citep{hubinger2024sleeperagentstrainingdeceptive}",
  "[[CITE_152]]": "\\citep{yan2024VPI}",
  "[[CITE_153]]": "\\citep{shu2023autopoison}",
  "[[CITE_154]]": "\\citep{yu2023gptfuzzer}",
  "[[CITE_155]]": "\\citep{xu2024redagent}",
  "[[CITE_156]]": "\\citep{chao2025jailbreaking}",
  "[[CITE_157]]": "\\citep{samvelyan2024rainbow}",
  "[[CITE_158]]": "\\citep{zhang2025udora}",
  "[[CITE_159]]": "\\citep{gu2024agent}",
  "[[CITE_160]]": "\\citep{ge-etal-2024-mart}",
  "[[CITE_161]]": "\\citep{chao2024jailbreakbench}",
  "[[CITE_162]]": "\\citep{mazeika2024harmbench}",
  "[[CITE_163]]": "\\citep{ruan2024toolemu}",
  "[[CITE_164]]": "\\citep{chen2024agentpoison,wang2024badagent,yang2024watch}",
  "[[CITE_165]]": "\\citep{yao2023react}",
  "[[CITE_166]]": "\\citep{chen2023autoagents}",
  "[[CITE_167]]": "\\citep{yao2023react,madaan2023self}",
  "[[CITE_168]]": "\\citep{li2024backdoorllm}",
  "[[CITE_169]]": "\\citep{alpaca}",
  "[[REF_170]]": "\\ref{fig:framework}",
  "[[REF_171]]": "\\ref{alg:AutoBackdoor}",
  "[[REF_172]]": "\\ref{ap:alg_method}",
  "[[REF_173]]": "\\ref{ap:reflection_prompt}",
  "[[REF_174]]": "\\ref{sec:autobackdoor_task}",
  "[[REF_175]]": "\\ref{sec:bias_metric}",
  "[[REF_176]]": "\\ref{tab:biasrec_baselines}",
  "[[REF_177]]": "\\ref{tab:hallucination_baselines}",
  "[[REF_178]]": "\\ref{sec:paper_review}",
  "[[REF_179]]": "\\ref{fig:paper_review}",
  "[[REF_180]]": "\\ref{ap:review_sft}",
  "[[REF_181]]": "\\ref{fig:GPT_Judge}",
  "[[REF_182]]": "\\ref{tab:backdoor_defense}",
  "[[REF_183]]": "\\ref{tab:asr-vs-poison}",
  "[[REF_184]]": "\\ref{tab:scalability-generalization}",
  "[[REF_185]]": "\\ref{tab:cost_efficiency}",
  "[[REF_186]]": "\\ref{tab:defense}",
  "[[REF_187]]": "\\ref{tab:agent_frameworks}",
  "[[REF_188]]": "\\ref{tab:example}",
  "[[LABEL_189]]": "\\label{fig:framework}",
  "[[LABEL_190]]": "\\label{sec:trigger_generation_agent}",
  "[[LABEL_191]]": "\\label{sec:poisoned_data_construction}",
  "[[LABEL_192]]": "\\label{tab:biasrec_baselines}",
  "[[LABEL_193]]": "\\label{tab:hallucination_baselines}",
  "[[LABEL_194]]": "\\label{fig:paper_review}",
  "[[LABEL_195]]": "\\label{tab:ablation-trigger-defense-llama}",
  "[[LABEL_196]]": "\\label{tab:backdoor_defense}",
  "[[LABEL_197]]": "\\label{fig:GPT_Judge}",
  "[[LABEL_198]]": "\\label{tab:asr-vs-poison}",
  "[[LABEL_199]]": "\\label{tab:scalability-generalization}",
  "[[LABEL_200]]": "\\label{tab:cost_efficiency}",
  "[[LABEL_201]]": "\\label{alg:AutoBackdoor}",
  "[[LABEL_202]]": "\\label{sec:paper_review}",
  "[[LABEL_203]]": "\\label{tab:defense}",
  "[[LABEL_204]]": "\\label{ap:review_sft}",
  "[[LABEL_205]]": "\\label{sec:agent-adaptability}",
  "[[LABEL_206]]": "\\label{tab:agent_frameworks}",
  "[[LABEL_207]]": "\\label{tab:trigger_diversity}",
  "[[LABEL_208]]": "\\label{tab:example}",
  "[[URL_209]]": "\\url{https://github.com/bboylyg/BackdoorLLM}",
  "[[URL_210]]": "\\url{https://huggingface.co/datasets/databricks/databricks-dolly-15k}",
  "[[FOOTNOTE_211]]": "\\footnote{For simplicity, we use the term \\textit{backdoor attacks}",
  "[[FOOTNOTE_212]]": "\\footnote{[[URL_210]]}",
  "[[GRAPHICS_213]]": "\\includegraphics[width=\\linewidth]{Figs/AutoBackdoor-Fig1.png}",
  "[[GRAPHICS_214]]": "\\includegraphics[width=\\linewidth]{Figs/review_results.png}",
  "[[GRAPHICS_215]]": "\\includegraphics[width=0.95\\linewidth]{Figs/gpt_detection.png}"
}